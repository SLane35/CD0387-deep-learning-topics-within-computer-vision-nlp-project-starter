# Image Classification using AWS SageMaker

Use AWS Sagemaker to train a pretrained model that can perform image classification by using the Sagemaker profiling, debugger, hyperparameter tuning and other good ML engineering practices. This can be done on either the provided dog breed classification data set or one of your choice.

## Project Set Up and Installation
Enter AWS through the gateway in the course and open SageMaker Studio. 
Download the starter files.
Download/Make the dataset available. 

## Dataset
The provided dataset is the dogbreed classification dataset which can be found in the classroom.
The project is designed to be dataset independent so if there is a dataset that is more interesting or relevant to your work, you are welcome to use it to complete the project.

### Access
Upload the data to an S3 bucket through the AWS Gateway so that SageMaker has access to the data. 

## Files
The following files are included in the repository:
1. train_and_deploy.ipynb - this is the main file; it downloads the dataset, runs the hyperparameter tuning, trains the model with the debug and profiler hooks, and then deploys the model and queries the endpoint.
2. hpo.py - this is the file used for hyperparameter tuning
3. train_model.py - this is the file used for training the model. It includes hooks for the debugger and profiler
4. profiler-report.html - this is the report that is generated by the profiler
5. hpt-logs.jpg, endpoint.png, best-parameters.jpg, hyperparameter-tuning.png = these are screenshots used in the Readme file

## Hyperparameter Tuning
The pretrained model of choice for this project is Resnet18. Resnet is one of the best-performing pretrained datasets used for image recognition. 

For the hyperparameter tuning, I included the following hyperparameters and ranges:

1. learning rate (lr) with a range of .001 - .1
2. batch size with options 16, 32, 64, 128
3. epochs with a range of 2 to 5

These hyperparameters were chosen because they have the greatest effect on a model's performance. I call the hpo python file from the train_and_deploy notebook to complete the hyperparameter tuning.

Hyperparameter tuning jobs successfully completed
![](hyperparameter-tuning.png)

Log metrics from hyperparameter tuning job
![](hpt-logs.jpg)

Best parameters
![](best-parameters.jpg)

## Debugging and Profiling
Next, I performed model debugging and profiling. I created rules for the profiler, such as loss_not_decreasing and overfit. I then set the profiler and debugger configuration settings and trained the model, making sure to embed the debug/profilng hooks within the training code. The training code is stored in the train_model.py file and is called from  the train_and_deploy notebook. 

Following is the debugger output from training the model:
2021-12-28 20:09:48 Starting - Starting the training job...
2021-12-28 20:10:15 Starting - Launching requested ML instancesLossNotDecreasing: InProgress
VanishingGradient: InProgress
Overfit: InProgress
Overtraining: InProgress
PoorWeightInitialization: InProgress
LowGPUUtilization: InProgress
ProfilerReport: InProgress
......
2021-12-28 20:11:15 Starting - Preparing the instances for training.........
2021-12-28 20:12:44 Downloading - Downloading input data............
2021-12-28 20:14:44 Training - Downloading the training image...........bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
2021-12-28 20:16:30,975 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training
2021-12-28 20:16:30,997 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.
2021-12-28 20:16:34,043 sagemaker_pytorch_container.training INFO     Invoking user training script.
2021-12-28 20:16:34,972 sagemaker-training-toolkit INFO     Invoking user script
Training Env:
{
    "additional_framework_parameters": {},
    "channel_input_dirs": {
        "train": "/opt/ml/input/data/train"
    },
    "current_host": "algo-1",
    "framework_module": "sagemaker_pytorch_container.training:main",
    "hosts": [
        "algo-1"
    ],
    "hyperparameters": {
        "batch_size": "32",
        "lr": "0.005010591629383133",
        "epochs": "3"
    },
    "input_config_dir": "/opt/ml/input/config",
    "input_data_config": {
        "train": {
            "TrainingInputMode": "File",
            "S3DistributionType": "FullyReplicated",
            "RecordWrapperType": "None"
        }
    },
    "input_dir": "/opt/ml/input",
    "is_master": true,
    "job_name": "pytorch-training-2021-12-28-20-09-48-131",
    "log_level": 20,
    "master_hostname": "algo-1",
    "model_dir": "/opt/ml/model",
    "module_dir": "s3://sagemaker-us-east-1-847017168036/pytorch-training-2021-12-28-20-09-48-131/source/sourcedir.tar.gz",
    "module_name": "train_model",
    "network_interface_name": "eth0",
    "num_cpus": 8,
    "num_gpus": 1,
    "output_data_dir": "/opt/ml/output/data",
    "output_dir": "/opt/ml/output",
    "output_intermediate_dir": "/opt/ml/output/intermediate",
    "resource_config": {
        "current_host": "algo-1",
        "hosts": [
            "algo-1"
        ],
        "network_interface_name": "eth0"
    },
    "user_entry_point": "train_model.py"
}
Environment variables:
SM_HOSTS=["algo-1"]
SM_NETWORK_INTERFACE_NAME=eth0
SM_HPS={"batch_size":"32","epochs":"3","lr":"0.005010591629383133"}
SM_USER_ENTRY_POINT=train_model.py
SM_FRAMEWORK_PARAMS={}
SM_RESOURCE_CONFIG={"current_host":"algo-1","hosts":["algo-1"],"network_interface_name":"eth0"}
SM_INPUT_DATA_CONFIG={"train":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}}
SM_OUTPUT_DATA_DIR=/opt/ml/output/data
SM_CHANNELS=["train"]
SM_CURRENT_HOST=algo-1
SM_MODULE_NAME=train_model
SM_LOG_LEVEL=20
SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main
SM_INPUT_DIR=/opt/ml/input
SM_INPUT_CONFIG_DIR=/opt/ml/input/config
SM_OUTPUT_DIR=/opt/ml/output
SM_NUM_CPUS=8
SM_NUM_GPUS=1
SM_MODEL_DIR=/opt/ml/model
SM_MODULE_DIR=s3://sagemaker-us-east-1-847017168036/pytorch-training-2021-12-28-20-09-48-131/source/sourcedir.tar.gz
SM_TRAINING_ENV={"additional_framework_parameters":{},"channel_input_dirs":{"train":"/opt/ml/input/data/train"},"current_host":"algo-1","framework_module":"sagemaker_pytorch_container.training:main","hosts":["algo-1"],"hyperparameters":{"batch_size":"32","epochs":"3","lr":"0.005010591629383133"},"input_config_dir":"/opt/ml/input/config","input_data_config":{"train":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}},"input_dir":"/opt/ml/input","is_master":true,"job_name":"pytorch-training-2021-12-28-20-09-48-131","log_level":20,"master_hostname":"algo-1","model_dir":"/opt/ml/model","module_dir":"s3://sagemaker-us-east-1-847017168036/pytorch-training-2021-12-28-20-09-48-131/source/sourcedir.tar.gz","module_name":"train_model","network_interface_name":"eth0","num_cpus":8,"num_gpus":1,"output_data_dir":"/opt/ml/output/data","output_dir":"/opt/ml/output","output_intermediate_dir":"/opt/ml/output/intermediate","resource_config":{"current_host":"algo-1","hosts":["algo-1"],"network_interface_name":"eth0"},"user_entry_point":"train_model.py"}
SM_USER_ARGS=["--batch_size","32","--epochs","3","--lr","0.005010591629383133"]
SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate
SM_CHANNEL_TRAIN=/opt/ml/input/data/train
SM_HP_BATCH_SIZE=32
SM_HP_LR=0.005010591629383133
SM_HP_EPOCHS=3
PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages
Invoking script with the following command:
/opt/conda/bin/python3.6 train_model.py --batch_size 32 --epochs 3 --lr 0.005010591629383133

2021-12-28 20:16:45 Training - Training image download completed. Training in progress.[2021-12-28 20:16:39.241 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None
[2021-12-28 20:16:39.422 algo-1:26 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.
Running on Device cuda:0
[2021-12-28 20:16:46.897 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.
[2021-12-28 20:16:46.899 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.
[2021-12-28 20:16:46.901 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors
[2021-12-28 20:16:46.901 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.
[2021-12-28 20:16:46.917 algo-1:26 INFO hook.py:591] name:fc.0.weight count_params:262144
[2021-12-28 20:16:46.918 algo-1:26 INFO hook.py:591] name:fc.0.bias count_params:512
[2021-12-28 20:16:46.918 algo-1:26 INFO hook.py:591] name:fc.2.weight count_params:68096
[2021-12-28 20:16:46.919 algo-1:26 INFO hook.py:591] name:fc.2.bias count_params:133
[2021-12-28 20:16:46.919 algo-1:26 INFO hook.py:593] Total Trainable Params: 330885
32
Start Model Training
Epoch 0, Phase train
[2021-12-28 20:16:48.189 algo-1:26 INFO hook.py:425] Monitoring the collections: CrossEntropyLoss_output_0, gradients, losses, relu_input
[2021-12-28 20:16:48.190 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/prestepzero-*-start-1640722599422949.2_train-0-stepstart-1640722608190325.2/python_stats.
[2021-12-28 20:16:48.209 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26
[2021-12-28 20:16:59.912 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-stepstart-1640722608201417.8_train-0-forwardpassend-1640722619911548.5/python_stats.
[2021-12-28 20:17:00.378 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-forwardpassend-1640722619915047.8_train-1-stepstart-1640722620377656.2/python_stats.
train loss: 76.0000, acc: 13.0000, best loss: 1000000.0000
Epoch 0, Phase valid
LossNotDecreasing: InProgress
VanishingGradient: InProgress
Overfit: InProgress
Overtraining: InProgress
PoorWeightInitialization: IssuesFound
valid loss: 35.0000, acc: 20.0000, best loss: 35.0000
Epoch 1, Phase train
LossNotDecreasing: InProgress
VanishingGradient: InProgress
Overfit: Error
Overtraining: IssuesFound
PoorWeightInitialization: IssuesFound
train loss: 34.0000, acc: 21.0000, best loss: 35.0000
Epoch 1, Phase valid
valid loss: 29.0000, acc: 21.0000, best loss: 29.0000
Epoch 2, Phase train
train loss: 28.0000, acc: 22.0000, best loss: 29.0000
Epoch 2, Phase valid
valid loss: 32.0000, acc: 21.0000, best loss: 29.0000
Testing Model

2021-12-28 20:22:10 Uploading - Uploading generated training modelTesting Accuracy: 17, Testing Loss: 53.0
Saving Model
INFO:__main__:Running on Device cuda:0
Downloading: "https://download.pytorch.org/models/resnet18-5c106cde.pth" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth
#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 14%|█▍        | 6.41M/44.7M [00:00<00:00, 67.2MB/s]#015 29%|██▊       | 12.8M/44.7M [00:00<00:00, 66.3MB/s]#015 43%|████▎     | 19.2M/44.7M [00:00<00:00, 66.4MB/s]#015 57%|█████▋    | 25.5M/44.7M [00:00<00:00, 66.3MB/s]#015 71%|███████▏  | 31.8M/44.7M [00:00<00:00, 65.6MB/s]#015 85%|████████▌ | 38.1M/44.7M [00:00<00:00, 65.6MB/s]#015 99%|█████████▉| 44.4M/44.7M [00:00<00:00, 65.3MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 65.6MB/s]
INFO:__main__:32
INFO:__main__:Start Model Training
INFO:__main__:Epoch 0, Phase train
INFO:__main__:train loss: 76.0000, acc: 13.0000, best loss: 1000000.0000
INFO:__main__:Epoch 0, Phase valid
INFO:__main__:valid loss: 35.0000, acc: 20.0000, best loss: 35.0000
INFO:__main__:Epoch 1, Phase train
INFO:__main__:train loss: 34.0000, acc: 21.0000, best loss: 35.0000
INFO:__main__:Epoch 1, Phase valid
INFO:__main__:valid loss: 29.0000, acc: 21.0000, best loss: 29.0000
INFO:__main__:Epoch 2, Phase train
INFO:__main__:train loss: 28.0000, acc: 22.0000, best loss: 29.0000
INFO:__main__:Epoch 2, Phase valid
INFO:__main__:valid loss: 32.0000, acc: 21.0000, best loss: 29.0000
INFO:__main__:Testing Model
INFO:__main__:Testing Accuracy: 17, Testing Loss: 53.0
INFO:__main__:Saving Model
2021-12-28 20:22:07,302 sagemaker-training-toolkit INFO     Reporting training SUCCESS

2021-12-28 20:22:49 Completed - Training job completed
LossNotDecreasing: NoIssuesFound
VanishingGradient: NoIssuesFound
Overfit: Error
Overtraining: IssuesFound
PoorWeightInitialization: IssuesFound
LowGPUUtilization: IssuesFound
ProfilerReport: IssuesFound
Training seconds: 579
Billable seconds: 579


As seen from the output, there are several issues with the model, such as overfitting, poor weight initialization, and low gpu utilization.

### Results
The model performed well overall. There were some recommendations such as increaasing the batch size or minimizing blocking calls. See more details in the profiler-report.html file.

## Model Deployment
The model is deployed to an aws endpoint and is queried using the predict function with the payload (as a series of bytes) and the content type (Image/jpeg) as parameters. I created a special class ImagePredictor that includes the endpoint name and sagemaker session, as well as a jpeg and json deserializer. I use this class as the parameter for predictor_cls when creating the PyTorchModel that is going to be deployed. Once the model is deployed, I query the model using the following code:

with open("test image.jpg", "rb") as f: 
    payload = f.read()
response=predictor.predict(payload, initial_args={"ContentType": "image/jpeg"})

The response is a list of 133 numbers representing the 133 dog breed classes. The highest number represents the highest probability that the image is of that class. For example, in our notebook, the 50th number is the highest, hence it predicts that the picture is of a dog from the breed of the 50th class (a Chinese shar-pei). 

I use the following code to get the highest number: np.argmax(response, 1)

Incidentally, the image is actually of a Chow-chow, but it looks similar to the Chinese shar-pei.

The active endpoint
![](endpoint.png)
